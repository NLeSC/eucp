= Potential system configurations

== Kubernetes

The default system configuration for BinderHub is a Kubernetes system: multiple pods, each pod with a specific Docker container for a specific user.
The Docker container is created with the `repo2docker`.

The advantage of this system is that it scales really simple, using the scaling capabilities and administration of Kubernetes.
The disadvantage is communication between pods.
Usually, this is not an issue, because the pods (and thus Docker containers and their users) should be able to work in isolation.
Given some of issues (requirements, really) listed in the link:development.adoc#technical-challenges[development documentation (section "technical challenges")], however, more direct communication between pods and containers may be required: read-only access to share data and scripts between different users, read-only access for (permanent) data on the server, read-and-write access for intermediate data.
Usually, such data access is through a network protocol: http is the standard protocol between BinderHub and JupyterHub, for example.
Solutions for data access on a Kubernetes system exist, often through a specialized data store (like S3).
This, however, may be slow or generally inconvenient, especially in the case of transferring many or large files.

== Single (virtual) machine, many containers

Using a single machine would allow for use of the usual Unix-style permissions: user, group and world read, write and execute.
This, however, would lose the possibility of running separate containers for each user.
The containers provide some safety of users impacting the system, as well as the option of creating a completely independent and specialized  environment for each user to work in.

It should still be possible to use BinderHub on this sytem: BinderHub would fire up a Docker container (with help of `repo2docker`) for each user that logs in.
The containers could then have optional connections (mounts) to the local file system, which makes local data access possible.
User data storage, for example a specific `/home/` directory, should also be possible, if users are logged in using accounts on the local system.
For the user storage to work, users should then write their files to a special directory inside their container, which connects to this home directory on the local system.

This would allow the full possibilities of a Unix-like system, including management of users, such as data use limitations (for example, maximum allowed storage in their home directory).

In addition, it may be possible to provide users with direct ssh access to the machine.
This has the disadvantage that limitations on resources for a particular user are harder to configure, or simply not available, since there is no containerization anymore.
There is also no option for directly viewing results (through, for example notebook PNG images, or even interactively using a JavaScript visualization library).
Ssh access also requires a different account (login system) than using the aforementioned OpenID through ESGF, and may bring potential issues regarding data file usage.
Ssh access would likely thus be for a set of restricted users, if at all.
